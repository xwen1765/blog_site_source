"use strict";(self.webpackChunkhaochen_blog=self.webpackChunkhaochen_blog||[]).push([[6111],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>f});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function s(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function i(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):s(s({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},p="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},h=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,u=i(e,["components","mdxType","originalType","parentName"]),p=c(a),h=r,f=p["".concat(l,".").concat(h)]||p[h]||d[h]||o;return a?n.createElement(f,s(s({ref:t},u),{},{components:a})):n.createElement(f,s({ref:t},u))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,s=new Array(o);s[0]=h;var i={};for(var l in t)hasOwnProperty.call(t,l)&&(i[l]=t[l]);i.originalType=e,i[p]="string"==typeof e?e:r,s[1]=i;for(var c=2;c<o;c++)s[c]=a[c];return n.createElement.apply(null,s)}return n.createElement.apply(null,a)}h.displayName="MDXCreateElement"},3924:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var n=a(7462),r=(a(7294),a(3905));const o={slug:"upload-files-to-s3-iwth-node",title:"How to Upload Files to AWS S3 in Node.js?",author:"Haochen Qi",author_title:"Full Stack Developer",author_url:"https://github.com/HaochenQ",author_image_url:"https://avatars1.githubusercontent.com/u/44130343?s=400&u=a5a4729addf5c5b972d1d6220546273ff6e00eb4&v=4",tags:["Node.js","AWS S3","Bucket Operation"]},s=void 0,i={permalink:"/zh-cn/blog/upload-files-to-s3-iwth-node",source:"@site/i18n/zh-cn/docusaurus-plugin-content-blog/2021-05-31-upload-files-to-s3-in-node.md",title:"How to Upload Files to AWS S3 in Node.js?",description:"question",date:"2021-05-31T00:00:00.000Z",formattedDate:"2021\u5e745\u670831\u65e5",tags:[{label:"Node.js",permalink:"/zh-cn/blog/tags/node-js"},{label:"AWS S3",permalink:"/zh-cn/blog/tags/aws-s-3"},{label:"Bucket Operation",permalink:"/zh-cn/blog/tags/bucket-operation"}],readingTime:4.07,hasTruncateMarker:!0,authors:[{name:"Haochen Qi",title:"Full Stack Developer",url:"https://github.com/HaochenQ",imageURL:"https://avatars1.githubusercontent.com/u/44130343?s=400&u=a5a4729addf5c5b972d1d6220546273ff6e00eb4&v=4"}],frontMatter:{slug:"upload-files-to-s3-iwth-node",title:"How to Upload Files to AWS S3 in Node.js?",author:"Haochen Qi",author_title:"Full Stack Developer",author_url:"https://github.com/HaochenQ",author_image_url:"https://avatars1.githubusercontent.com/u/44130343?s=400&u=a5a4729addf5c5b972d1d6220546273ff6e00eb4&v=4",tags:["Node.js","AWS S3","Bucket Operation"]},prevItem:{title:"\u7406\u89e3 JavaScript \u4e2d\u7684 This, Bind, Call \u548c Apply",permalink:"/zh-cn/blog/understand-this-in-one-article"},nextItem:{title:"Shallow Copy vs. Deep Copy",permalink:"/zh-cn/blog/understand-copy-in-js"}},l={authorsImageUrls:[void 0]},c=[{value:"Create a S3 Bucket",id:"create-a-s3-bucket",level:2},{value:"Create a Simple Node App",id:"create-a-simple-node-app",level:2},{value:"Interact With Our Bucket",id:"interact-with-our-bucket",level:2},{value:"Conclusion",id:"conclusion",level:2}],u={toc:c},p="wrapper";function d(e){let{components:t,...o}=e;return(0,r.kt)(p,(0,n.Z)({},u,o,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"question",src:a(1329).Z,width:"700",height:"300"})),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Amazon Simple Storage Service is storage for the Internet. It is designed to make web-scale computing easier for developers. -- Amazon")),(0,r.kt)("p",null,"Simple Storage Service(S3) is a an object storage service provided by AWS in 2006. S3 provides developers with a distributed data storage service with high scalability, high durability and high availability. The data storage structure of S3 is very simple, which is a flat two-layer structure: one layer is a bucket, and the other layer is a storage object. A bucket is a way to classify data in S3, it is a container for data storage and every object needs to be stored in a certain bucket. It will become a part of the domain name for users to access data, so the name of the bucket must be unique."),(0,r.kt)("p",null,"Our Node Apps often need to store user data like images, audio files, documents ,etc into somewhere secure and easily accessible instead of on local server. This is when S3 comes in as a perfect option. In this blog, we will go through how to upload your files in AWS s3 buckets."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"question",src:a(7838).Z,width:"596",height:"425"})),(0,r.kt)("h2",{id:"create-a-s3-bucket"},"Create a S3 Bucket"),(0,r.kt)("p",null,"In this section, we will create a bucket on S3 for us to upload files in. To get start, you need to generate AWS Security Key Access Credentials first from your AWS Management console."),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"question",src:a(8798).Z,width:"2432",height:"1078"})),(0,r.kt)("p",null,"On the AWS Services panel, find IAM and click to go IAM dashboard. Under the Access Management section, find Users >> Add User.\n",(0,r.kt)("img",{alt:"question",src:a(2388).Z,width:"2018",height:"1042"}),"\nThen follow the steps to create a programmatic access AWS user attached with ",(0,r.kt)("strong",{parentName:"p"},"AmazonS3FullAccess")," policy. ",(0,r.kt)("em",{parentName:"p"},"Save your access key ID and secret access key in a secure place as you won't able to check them again."),"\n",(0,r.kt)("img",{alt:"question",src:a(8680).Z,width:"1910",height:"1148"})),(0,r.kt)("p",null,"Now let us create a bucket with a unique name. Similarly, find S3 On the AWS Services pane. On the dashboard, click ",(0,r.kt)("strong",{parentName:"p"},"Create bucket")," to create a new bucket with proper region and other default settings. After you create a bucket, we need to allow our client application to interact with our bucket. Go to Your Bucket >> Permissions >> Cross-origin resource sharing (CORS). Change the configuration as bellow."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'[\n  {\n    "AllowedHeaders": ["*"],\n    "AllowedMethods": ["POST", "GET", "PUT", "DELETE", "HEAD"],\n    "AllowedOrigins": ["*"],\n    "ExposeHeaders": []\n  }\n]\n')),(0,r.kt)("p",null,"Now, We have a bucket up for us to play with. Alternatively, you can also create a bucket with AWS SDK tool. Simply felllow ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-creating-buckets.html"},"here"),"."),(0,r.kt)("h2",{id:"create-a-simple-node-app"},"Create a Simple Node App"),(0,r.kt)("p",null,"Now let us interact with our created bucket. Before we create a S3 instance, make sure to put sensitive data in the environment variables, simply create a .env file and save your data in that file. Here I will use a library called dotenv to handle .env file, it will loads environment variables from a .env file into process.env."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"AWS_ACCESS_KEY_ID=Your AWS Access Key ID\nAWS_SECRET_ACCESS_KEY=Your AWS Secret Access Key\nS3_BUCKET=Your Bucket Name\n")),(0,r.kt)("p",null,"Then let's create a S3 instance after we install all necessary dependencies with:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$ npm i dotenv aws-sdk\n")),(0,r.kt)("p",null,"Create a file name with app.js, let's write code in this file."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'require("dotenv").config();\n\nconst fs = require("fs");\nconst AWS = require("aws-sdk");\n\nconst s3 = new AWS.S3({\n  accessKeyId: process.env.AWS_ACCESS_KEY_ID,\n  secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,\n});\n')),(0,r.kt)("h2",{id:"interact-with-our-bucket"},"Interact With Our Bucket"),(0,r.kt)("p",null,"With the S3 instance set up, we can now play with our bucket. We can upload files to our bucket, get all the files in our bucket and delete files.\nBefore we upload the file, we need to read its contents in a buffer. After reading it, we can define the needed parameters for the file upload, such as Bucket, Key, and Body.Let's see the code."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'/**\n * Upload files\n **/\nconst uploadToS3 = async (file) => {\n  // Read content from the file\n  const fileContent = fs.readFileSync(file);\n\n  // Setting up S3 upload parameters\n  const params = {\n    Bucket: process.env.S3_BUCKET,\n    Key: "your_image.jpg", // File name you want to save as in S3\n    Body: fileContent,\n  };\n\n  // Uploading files to the bucket\n  s3.upload(params, function (err, data) {\n    if (err) {\n      throw err;\n    }\n    console.log(`File uploaded successfully. ${data.Location}`);\n  });\n};\nuploadToS3("your_image.jpg");\n')),(0,r.kt)("p",null,"If you want to list all objects in your bucket, you can use S3 ",(0,r.kt)("strong",{parentName:"p"},"listObjectsV2")," function."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-javascript"},'/**\n * List all objects in the bucket\n */\ngetlist = async () => {\n  const params = {\n    Bucket: process.env.S3_BUCKET,\n    Delimiter: "",\n  };\n  try {\n    const response = await s3.listObjectsV2(params).promise();\n    this.setState({\n      list: response.Contents,\n      fetched: true,\n    });\n    console.log(this.state.list);\n  } catch (err) {\n    this.setState({\n      ifError: true,\n      errorCode: err.code,\n    });\n    console.log("S3 ERROR : " + err.code);\n  }\n};\nconsloe.log(getlist());\n')),(0,r.kt)("p",null,"Now run your js file to see the result."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"$node app.js\n")),(0,r.kt)("h2",{id:"conclusion"},"Conclusion"),(0,r.kt)("p",null,"In this blog, we created simple Node App and interact with our bucket. Nowadays, using a cloud storage service like AWS S3 is a very popular way to reduce storage pressure for servers as well as securly store user data."),(0,r.kt)("hr",null),(0,r.kt)("p",null,"Reference: ",(0,r.kt)("a",{parentName:"p",href:"https://docs.aws.amazon.com/sdk-for-javascript/v2/developer-guide/s3-example-creating-buckets.html"},"AWS S3 Doc")))}d.isMDXComponent=!0},2388:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/IAM-user-8830dec278f95e55448ad8f04bba3a69.png"},8798:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/IAM-53d1e547aae70ce30782db0c354a30cf.png"},1329:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/S3-d97bff68b818a19877f0025305163cfc.jpg"},7838:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/bucket-fe258a8666d449e47fd43ac00a3a8283.png"},8680:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/s3-permission-1f53d0d274f3c8fcf1ddbc59cb0e9aef.png"}}]);